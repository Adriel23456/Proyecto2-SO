# ğŸš€ ClÃºster Beowulf **HeterogÃ©neo** con **OpenMPI** â€” ARM7 + x86_64

> **Arquitectura:** Master en Raspberry Pi OS (ARM7 32-bit) + Slaves en Ubuntu (x86_64)  
> **MPI:** OpenMPI 4.1.6 con soporte heterogÃ©neo completo  
> **Objetivo:** Ejecutar procesos MPI distribuidos entre arquitecturas diferentes

---

## ğŸ“‹ Pre-requisitos

- Raspberry Pi con Raspberry Pi OS (32-bit ARM7)
- PCs/VMs con Ubuntu 22.04/24.04 (x86_64)
- ConexiÃ³n de red entre todos los nodos
- Usuario comÃºn en todos los nodos (ej: `adriel`)

---

## 0) ConfiguraciÃ³n de red y nombres

### En TODOS los nodos:

1. **Crear usuario comÃºn** (si no existe):
```bash
sudo adduser adriel
sudo usermod -aG sudo adriel
su - adriel
```

2. **Obtener IPs de cada nodo**:
```bash
hostname -I | awk '{print $1}'
```

3. **Configurar `/etc/hosts`** (ajusta con tus IPs):
```bash
sudo nano /etc/hosts
```

Contenido ejemplo:
```
192.168.18.242  raspberrypi master
192.168.18.10   slave1 dominio1
192.168.18.241  slave2 dominio2
192.168.18.90   slave3 dominio3
```

4. **Verificar conectividad**:
```bash
ping -c 2 master
ping -c 2 slave1
```

---

## 1) InstalaciÃ³n de SSH

### En TODOS los nodos:
```bash
sudo apt update
sudo apt install -y openssh-server openssh-client
sudo systemctl enable --now ssh
sudo systemctl status ssh
```

---

## 2) InstalaciÃ³n de OpenMPI 4.1.6 con soporte heterogÃ©neo

### âš ï¸ IMPORTANTE: Usar exactamente la misma versiÃ³n y prefijo en TODOS los nodos

### En Raspberry Pi (ARM7 32-bit - Master) (Nota: Se tendran que corregir manualmente archivos por retrocompatibilidad en el 'make')
```bash
# Limpiar cualquier instalaciÃ³n previa de OpenMPI
sudo rm -rf /opt/openmpi* /usr/local/openmpi*
sed -i '/openmpi/Id' ~/.bashrc
source ~/.bashrc

# Instalar dependencias
sudo apt update
sudo apt install -y build-essential gfortran libhwloc-dev libevent-dev

# Descargar OpenMPI 4.1.6
cd ~
wget https://download.open-mpi.org/release/open-mpi/v4.1/openmpi-4.1.6.tar.gz
tar xzf openmpi-4.1.6.tar.gz
cd openmpi-4.1.6

# Configurar para ARM7 32-bit con soporte heterogÃ©neo
./configure --prefix=/opt/openmpi-4.1.6 \
            --enable-heterogeneous \
            --enable-mpi-fortran=no \
            --enable-mpirun-prefix-by-default \
            --with-hwloc=internal \
            --with-libevent=internal \
            --disable-mpi-fortran \
            --enable-shared \
            --enable-static \
            CC=gcc CXX=g++ \
            CFLAGS="-O2 -march=armv7-a -mfpu=vfp -mfloat-abi=hard" \
            CXXFLAGS="-O2 -march=armv7-a -mfpu=vfp -mfloat-abi=hard"

# Compilar e instalar
make -j$(nproc)
sudo make install

# Configurar variables de entorno
echo 'export PATH=/opt/openmpi-4.1.6/bin:$PATH' >> ~/.bashrc
echo 'export LD_LIBRARY_PATH=/opt/openmpi-4.1.6/lib:$LD_LIBRARY_PATH' >> ~/.bashrc
source ~/.bashrc

# Registrar bibliotecas
echo '/opt/openmpi-4.1.6/lib' | sudo tee /etc/ld.so.conf.d/openmpi.conf
sudo ldconfig

# Verificar instalaciÃ³n
which mpicc
mpirun --version
ompi_info | grep -i heterogeneous
```

### En Slaves x86_64 (Ubuntu 64-bit)
```bash
# Limpiar instalaciones previas
sudo rm -rf /opt/openmpi* /usr/local/openmpi*
sed -i '/openmpi/Id' ~/.bashrc
source ~/.bashrc

# Instalar dependencias
sudo apt update
sudo apt install -y build-essential gfortran libhwloc-dev libevent-dev

# Descargar OpenMPI 4.1.6
cd ~
wget https://download.open-mpi.org/release/open-mpi/v4.1/openmpi-4.1.6.tar.gz
tar xzf openmpi-4.1.6.tar.gz
cd openmpi-4.1.6

# Configurar para x86_64 con soporte heterogÃ©neo
./configure --prefix=/opt/openmpi-4.1.6 \
            --enable-heterogeneous \
            --enable-mpi-fortran=no \
            --enable-mpirun-prefix-by-default \
            --with-hwloc=internal \
            --with-libevent=internal \
            --disable-mpi-fortran \
            --enable-shared \
            --enable-static \
            CC=gcc CXX=g++ \
            CFLAGS="-O2" \
            CXXFLAGS="-O2"

# Compilar e instalar
make -j$(nproc)
sudo make install

# Configurar variables de entorno
echo 'export PATH=/opt/openmpi-4.1.6/bin:$PATH' >> ~/.bashrc
echo 'export LD_LIBRARY_PATH=/opt/openmpi-4.1.6/lib:$LD_LIBRARY_PATH' >> ~/.bashrc
source ~/.bashrc

# Registrar bibliotecas
echo '/opt/openmpi-4.1.6/lib' | sudo tee /etc/ld.so.conf.d/openmpi.conf
sudo ldconfig

# Verificar instalaciÃ³n
which mpicc
mpirun --version
ompi_info | grep -i heterogeneous
```

---

## 3) ConfiguraciÃ³n SSH sin contraseÃ±a

### Desde el MASTER (Raspberry Pi):
```bash
# Generar llave SSH
[ -f ~/.ssh/id_ed25519 ] || ssh-keygen -t ed25519 -N "" -f ~/.ssh/id_ed25519

# Copiar llave a todos los nodos (incluido el master mismo)
ssh-copy-id -i ~/.ssh/id_ed25519.pub adriel@localhost
ssh-copy-id -i ~/.ssh/id_ed25519.pub adriel@slave1
ssh-copy-id -i ~/.ssh/id_ed25519.pub adriel@slave2
ssh-copy-id -i ~/.ssh/id_ed25519.pub adriel@slave3

# Verificar permisos
ssh adriel@localhost 'chmod 700 ~/.ssh; chmod 600 ~/.ssh/authorized_keys'
ssh adriel@slave1 'chmod 700 ~/.ssh; chmod 600 ~/.ssh/authorized_keys'
ssh adriel@slave2 'chmod 700 ~/.ssh; chmod 600 ~/.ssh/authorized_keys'
ssh adriel@slave3 'chmod 700 ~/.ssh; chmod 600 ~/.ssh/authorized_keys'

# Probar conexiÃ³n sin contraseÃ±a
ssh -o BatchMode=yes adriel@localhost 'echo OK_MASTER'
ssh -o BatchMode=yes adriel@slave1 'echo OK_SLAVE1'
ssh -o BatchMode=yes adriel@slave2 'echo OK_SLAVE2'
ssh -o BatchMode=yes adriel@slave3 'echo OK_SLAVE3'
```

---

## 4) Crear archivo de hosts para OpenMPI

### En el MASTER:
```bash
nano ~/.mpi_hostfile
```

Contenido (ajusta IPs y slots segÃºn tu configuraciÃ³n):
```
# Master (Raspberry Pi ARM7)
192.168.18.242 slots=2

# Slaves x86_64
192.168.18.10  slots=2
192.168.18.241 slots=2
192.168.18.90  slots=2
```

---

## 5) Preparar el programa de prueba

### Crear directorio de trabajo en TODOS los nodos:
```bash
cd ~/Documents/Proyecto2-SO/ClusterSystem
```

### Crear y compilar el programa en TODOS los nodos:
Se tiene en el repositorio ya descargado!

### Compilar en TODOS los nodos:
```bash
cd ~/Documents/Proyecto2-SO/ClusterSystem
/opt/openmpi-4.1.6/bin/mpicc -o ejemplo ejemplo.c
```

---

## 6) Script run_mpi_safe.sh mejorado

### Crear el script en el MASTER:
Se tiene en el repositorio ya descargado!

### Hacer ejecutable y copiar globalmente:
```bash
chmod +x ~/Documents/Proyecto2-SO/ClusterSystem/run_mpi_safe.sh
sudo cp ~/Documents/Proyecto2-SO/ClusterSystem/run_mpi_safe.sh /usr/local/bin/mpirun-safe
sudo chmod +x /usr/local/bin/mpirun-safe
```

---

## 7) EjecuciÃ³n del clÃºster

### MÃ©todo 1: Con script seguro (RECOMENDADO)
```bash
cd ~/Documents/Proyecto2-SO/ClusterSystem
mpirun-safe
```

### MÃ©todo 2: EjecuciÃ³n directa
```bash
cd ~/Documents/Proyecto2-SO/ClusterSystem
/opt/openmpi-4.1.6/bin/mpirun     -np 4     --hostfile ~/.mpi_hostfile     --map-by node     --bind-to core     --report-bindings     -x PATH     -x LD_LIBRARY_PATH     ./ejemplo
```

---

## 8) VerificaciÃ³n y troubleshooting

### Verificar conectividad SSH:
```bash
for host in localhost slave1 slave2 slave3; do
    echo -n "Testing $host: "
    ssh -o BatchMode=yes $host 'echo OK' 2>/dev/null && echo "âœ“" || echo "âœ—"
done
```

### Verificar OpenMPI en todos los nodos:
```bash
for host in localhost slave1 slave2 slave3; do
    echo "=== $host ==="
    ssh $host '/opt/openmpi-4.1.6/bin/ompi_info | grep -E "heterogeneous|Open MPI:"'
done
```

### Verificar que el ejecutable existe en todos los nodos:
```bash
for host in localhost slave1 slave2 slave3; do
    ssh $host "ls -l ~/Documents/Proyecto2-SO/ClusterSystem/ejemplo" 2>/dev/null || echo "$host: No encontrado"
done
```

### Test simple local:
```bash
cd ~/Documents/Proyecto2-SO/ClusterSystem
/opt/openmpi-4.1.6/bin/mpirun -np 2 ./ejemplo
```

---

## ğŸ“Œ Notas importantes

1. **Heterogeneidad**: OpenMPI 4.1.6 maneja automÃ¡ticamente las diferencias de arquitectura si se instalo con la retrocompatibilidad en mente
2. **SincronizaciÃ³n**: Todos los nodos deben tener el ejecutable en la misma ruta
3. **Bibliotecas**: Las rutas de OpenMPI deben ser idÃ©nticas en todos los nodos
4. **SSH**: La autenticaciÃ³n sin contraseÃ±a es obligatoria
5. **Firewall**: AsegÃºrate de que los puertos MPI no estÃ©n bloqueados

---

## ğŸ› ï¸ SoluciÃ³n de problemas comunes

### Error: "cannot open shared object file"
```bash
# En todos los nodos:
sudo ldconfig
source ~/.bashrc
```

### Error: "Permission denied (publickey)"
```bash
# Desde el master:
ssh-copy-id adriel@nodo_problemÃ¡tico
```

### Error: "heterogeneous run attempted"
```bash
# Verificar que --hetero estÃ© habilitado:
ompi_info | grep heterogeneous
# Debe mostrar: "Heterogeneous support: yes"
```

---

Â¡Con esta configuraciÃ³n tendrÃ¡s un clÃºster Beowulf heterogÃ©neo totalmente funcional! ğŸš€